{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning, Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adspy_shared_utilities import load_crime_dataset\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_bold = ListedColormap(['#FFFF00', '#00FF00', '#0000FF','#000000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_check(X, y):\n",
    "    import numpy as np\n",
    "    assert type(X) == type(np.zeros(2))\n",
    "#     assert X.shape[1] > 0\n",
    "    assert type(y) == type(np.zeros(y.shape))\n",
    "    try:\n",
    "        y.shape[1]\n",
    "        print('{} must be of shape: (n,)'.format(y.shape))  \n",
    "    except:\n",
    "        pass\n",
    "    if len(set(y)) > 9:\n",
    "        classes = 'regression'\n",
    "    else:\n",
    "        classes = set(y)\n",
    "    print('X:\\t {} {}\\ny:\\t {} {}\\nclasses: {}\\n'.format(X.shape, type(X), y.shape, type(y), classes))  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(X, y, **kwargs):\n",
    "    import matplotlib.cm as cm\n",
    "    import seaborn as sns\n",
    "    from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "    \n",
    "    title = kwargs.get('title', 'default Title')\n",
    "    label = kwargs.get('c', None)\n",
    "    \n",
    "    cmap = kwargs.get('cmap', cm.jet)\n",
    "    cols = ['#00570d', '#1dea5a', '#0762f1', '#cb00f7', '#ff02a0']  # very bright\n",
    "    col_pal = sns.color_palette(cols).as_hex()\n",
    "    cmap = ListedColormap(col_pal)\n",
    "    \n",
    "    plt.scatter(X, y, c=label, cmap=cmap, alpha=0.6)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntethic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification, make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for simple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_R1, y_R1 = make_regression(n_samples=100, n_features=1,\n",
    "                            n_informative=1, bias=150.0,\n",
    "                            noise=30, random_state=0)\n",
    "format_check(X_R1, y_R1)\n",
    "plot_dataset(X_R1, y_R1, title='Sample regression problem with one input variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for more complex regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)\n",
    "\n",
    "format_check(X_F1[:, 2], y_F1)\n",
    "plot_dataset(X_F1[:, 2], y_F1, title='Complex regression problem with one input variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for classification (binary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C2, y_C2 = make_classification(n_samples = 100, n_features=2,\n",
    "                                n_redundant=0, n_informative=2,\n",
    "                                n_clusters_per_class=1, flip_y = 0.1,\n",
    "                                class_sep = 0.5, random_state=0)\n",
    "\n",
    "format_check(X_C2[:, 0], X_C2[:, 1])\n",
    "plot_dataset(X_C2[:, 0], X_C2[:, 1], c=y_C2, title='Complex regression problem with one input variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for lineary unseparable classification (binary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_D2, y_D2 = make_blobs(n_samples=100, n_features=2, centers=8,\n",
    "                       cluster_std=1.3, random_state=4)\n",
    "y_D2 = y_D2 % 2\n",
    "\n",
    "format_check(X_D2[:,0], X_D2[:,1])\n",
    "plot_dataset(X_D2[:,0], X_D2[:,1], c=y_D2, title='Sample binary classification problem with non-linearly separable classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blobs for classification and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X_blob, y_blob = make_blobs(n_samples=500,\n",
    "                              n_features=2, \n",
    "                              centers=2, \n",
    "                              cluster_std=1.0,\n",
    "                              shuffle=True, \n",
    "                              random_state=0)\n",
    "\n",
    "format_check(X_blob, y_blob)\n",
    "plot_dataset(X_blob[:,0], X_blob[:,1], c=y_blob, title='Sample regression problem with one input variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast cancer dataset for classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer, y_cancer = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "format_check(X_cancer, y_cancer)\n",
    "plot_dataset(X_cancer[:,0], X_cancer[:,1], c=y_cancer, title='Breast Cancer dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crime_dataset():\n",
    "    # Communities and Crime dataset for regression\n",
    "    # https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized\n",
    "\n",
    "    crime = pd.read_table('../../_data/CommViolPredUnnormalizedData.txt', sep=',', na_values='?')\n",
    "    \n",
    "    # remove features with poor coverage or lower relevance, and keep ViolentCrimesPerPop target column\n",
    "    columns_to_keep = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]  \n",
    "    crime = crime.iloc[:,columns_to_keep].dropna()\n",
    "\n",
    "    X_crime = crime.iloc[:,range(0,88)]\n",
    "    y_crime = crime['ViolentCrimesPerPop']\n",
    "\n",
    "    return X_crime, y_crime, crime.columns\n",
    "\n",
    "X_crime, y_crime, crime_features = load_crime_dataset()\n",
    "X_crime, y_crime = X_crime.values, y_crime.values\n",
    "\n",
    "format_check(X_crime, y_crime)\n",
    "plot_dataset(X_crime[:,0], X_crime[:,1], c=y_crime, title='Crime dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = pd.read_table('../../_data/fruit_data_with_colors.txt')\n",
    "\n",
    "feature_names_fruits = ['height', 'width', 'mass', 'color_score']\n",
    "X_fruits = fruits[feature_names_fruits].values\n",
    "y_fruits = fruits['fruit_label'].values\n",
    "target_names_fruits = ['apple', 'mandarin', 'orange', 'lemon']\n",
    "\n",
    "X_fruits_2d = fruits[['height', 'width']].values\n",
    "y_fruits_2d = fruits['fruit_label'].values\n",
    "\n",
    "format_check(X_fruits_2d, y_fruits_2d)\n",
    "plot_dataset(X_fruits[:,0], X_fruits[:,1], c=y_fruits, title='Fruits dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression(model, coef, intercept, train_score, test_score, **kwargs):\n",
    "    non_zero_coef = kwargs.get('non_zero_coef', None)\n",
    "    features = kwargs.get('features', None)\n",
    "    \n",
    "    print('''\n",
    "    model:\\n    {}\n",
    "    linear model coeff (w):      {}\\n\n",
    "    linear model intercept (b):  {:.3f}\n",
    "    R-squared score (training):  {:.3f}\n",
    "    R-squared score (test):      {:.3f}\n",
    "    non-zero coeffs (test):      {}\n",
    "    '''.format(model, coef, intercept, train_score, test_score, non_zero_coef))\n",
    "    \n",
    "    if features is not None:\n",
    "        print('non-zero coeffs sorted by abs weight: ')\n",
    "        coeff_names = sorted(list(zip(features, np.round(coef, 3))), key = lambda e: -abs(e[1]))\n",
    "        for name, coeff in coeff_names:\n",
    "            if coeff != 0:\n",
    "                print('\\t', name, '=', coeff)\n",
    "    else:\n",
    "        coeff_names = None\n",
    "        \n",
    "def print_accuracy(title, train_score, test_score):\n",
    "    print('''\n",
    "    {}\n",
    "    Accuracy on training set: {:.2f}\n",
    "    Accuracy on test set:     {:.2f}'''.format(title, train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(**kwargs):\n",
    "    model = kwargs.get('model', None) \n",
    "    X = kwargs.get('X', None)\n",
    "    y = kwargs.get('y', None)\n",
    "    scaler = kwargs.get('scaler', None)\n",
    "    title = kwargs.get('title', None) \n",
    "    random_state = kwargs.get('random_state', 0)\n",
    "    plot = kwargs.get('plot', True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "    if scaler:\n",
    "        scaler = scaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    if not plot:\n",
    "        print_accuracy(title, model.score(X_train, y_train), model.score(X_test, y_test))\n",
    "        print('-'*80)\n",
    "    else:\n",
    "        ax = kwargs.get('ax', plt.gca())\n",
    "        plot_class_regions_for_classifier_subplot(model, X_train, y_train, X_test, y_test, title, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "datasets = [(X_C2, y_C2), (X_D2, y_D2), (X_fruits[:,:2], y_fruits), (X_cancer[:,:2], y_cancer)]\n",
    "datatitles = ['Classifier', 'Blob', 'fruits X0-X1', 'Breast cancer X0-X1']\n",
    "for title, (X, y), ax in zip(datatitles, datasets, subaxes.ravel()):\n",
    "    train_test(model=GaussianNB(),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Gaussian NB classifier: \\nDataset {}'.format(title),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "datasets = [(X_C2, y_C2), (X_D2, y_D2), (X_fruits[:,:2], y_fruits), (X_cancer[:,:2], y_cancer)]\n",
    "datatitles = ['Classifier', 'Blob', 'fruits X0-X1', 'Breast cancer X0-X1']\n",
    "for title, (X, y), ax in zip(datatitles, datasets, subaxes.ravel()):\n",
    "    train_test(model=GaussianNB(),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Gaussian NB classifier with scaler: \\nDataset {}'.format(title),\n",
    "               scaler=MinMaxScaler,\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "datasets = [(X_C2, y_C2), (X_D2, y_D2), (X_fruits[:,:2], y_fruits), (X_cancer[:,:2], y_cancer)]\n",
    "datatitles = ['Classifier', 'Blob', 'fruits X0-X1', 'Breast cancer X0-X1']\n",
    "for title, (X, y), ax in zip(datatitles, datasets, subaxes.ravel()):\n",
    "    train_test(model=RandomForestClassifier(),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Random Forest Classifier, default settings: \\nDataset {}'.format(title),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "datasets = [(X_C2, y_C2), (X_D2, y_D2), (X_fruits[:,:2], y_fruits), (X_cancer[:,:2], y_cancer)]\n",
    "datatitles = ['Classifier', 'Blob', 'fruits X0-X1', 'Breast cancer X0-X1']\n",
    "for title, (X, y), ax in zip(datatitles, datasets, subaxes.ravel()):\n",
    "    train_test(model=RandomForestClassifier(),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Random Forest Classifier, scaled: \\nDataset {}'.format(title),\n",
    "               scaler=MinMaxScaler,\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - tuning max. features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = [2, 3, 4]\n",
    "datasets = [(X_fruits, y_fruits)] * len(max_features)\n",
    "\n",
    "for max_f, (X, y) in zip(max_features, datasets):\n",
    "    train_test(model=RandomForestClassifier(max_features=max_f),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Random Forest Classifier, max. {} features: \\nDataset: Fruits'.format(title),\n",
    "               plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = [2, 5, 10, 15, 20, 25, 30]\n",
    "datasets = [(X_cancer, y_cancer)] * len(max_features)\n",
    "\n",
    "for max_f, (X, y) in zip(max_features, datasets):\n",
    "    train_test(model=RandomForestClassifier(max_features=max_f),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Random Forest Classifier, max. {} features: \\nDataset: Cancer'.format(title),\n",
    "               plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest: Fruit dataset pair-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "pair_list = [[0,1], [0,2], [0,3], [1,2], [1,3], [2,3]]\n",
    "datasets = [(X_fruits, y_fruits)] * len(pair_list)\n",
    "\n",
    "for (X, y), pair, ax in zip(datasets, pair_list, subaxes.ravel()):\n",
    "    train_test(model=RandomForestClassifier(),\n",
    "               X=X[:, pair], \n",
    "               y=y, \n",
    "               title='Random Forest Classifier, \\nFruits dataset {}'.format(pair),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "datasets = [(X_C2, y_C2), (X_D2, y_D2), (X_fruits[:,:2], y_fruits), (X_cancer[:,:2], y_cancer)]\n",
    "datatitles = ['Classifier', 'Blob', 'fruits X0-X1', 'Breast cancer X0-X1']\n",
    "for title, (X, y), ax in zip(datatitles, datasets, subaxes.ravel()):\n",
    "    train_test(model=GradientBoostingClassifier(),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Gradient Boosting, default settings \\nDataset {}'.format(title),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosted decision trees on the fruit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "pair_list = [[0,1], [0,2], [0,3], [1,2], [1,3], [2,3]]\n",
    "datasets = [(X_fruits, y_fruits)] * len(pair_list)\n",
    "\n",
    "for (X, y), pair, ax in zip(datasets, pair_list, subaxes.ravel()):\n",
    "    train_test(model=GradientBoostingClassifier(),\n",
    "               X=X[:, pair], \n",
    "               y=y, \n",
    "               title='Gradient Boosting, default settings \\nFruits features: {}'.format(pair),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient-boosted decision trees on a real-world dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "datasets = [(X_cancer, y_cancer)] * len(learning_rate)\n",
    "\n",
    "for depth in [2, 3, 4]:\n",
    "    max_depth = [depth] * len(learning_rate)\n",
    "\n",
    "    for max_d, lr, (X, y) in zip(max_depth, learning_rate, datasets):\n",
    "        train_test(model=GradientBoostingClassifier(learning_rate=lr, max_depth=max_d),\n",
    "                   X=X, \n",
    "                   y=y, \n",
    "                   title='Random Forest Classifier: Breast Cancer dataset\\n\\tlearning rate: {} \\n\\tmax. depth: {}'.format(lr, max_d),\n",
    "                   plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks: Multi-layer Perceptron(MPL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('axes.spines', left=True, top=False, right=False, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.linspace(-2, 2, 200)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "plt.plot(xrange, np.maximum(xrange, 0), label = 'relu')\n",
    "plt.plot(xrange, np.tanh(xrange), label = 'tanh')\n",
    "plt.plot(xrange, 1 / (1 + np.exp(-xrange)), label = 'logistic')\n",
    "plt.legend(frameon=False)\n",
    "plt.title('Neural network activation functions')\n",
    "plt.xlabel('Input value (x)')\n",
    "plt.ylabel('Activation function output')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_label_coords(0.9, 0.33)\n",
    "ax.yaxis.set_label_coords(0.49, 0.78)\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset axis\n",
    "mpl.rc('axes.spines', left=True, top=True, right=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic dataset 1: single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "units = [1, 2, 4, 8, 16, 32]\n",
    "datasets = [(X_D2, y_D2)] * len(units)\n",
    "\n",
    "for (X, y), units, ax in zip(datasets, units, subaxes.ravel()):\n",
    "    train_test(model=MLPClassifier(hidden_layer_sizes = [units], solver='lbfgs'),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Dataset 1: Neural net classifier, 1 layer, {} units'.format(units),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "hidden_layers = [1, 2, 4, 8, 16, 32]\n",
    "units_layer = 10\n",
    "datasets = [(X_D2, y_D2)] * len(hidden_layers)\n",
    "\n",
    "for (X, y), hidden_layers, ax in zip(datasets, hidden_layers, subaxes.ravel()):\n",
    "    train_test(model=MLPClassifier(hidden_layer_sizes = [units]*hidden_layers, solver='lbfgs'),\n",
    "               X=X, \n",
    "               y=y, \n",
    "               title='Dataset 1: Neural Net classifier, {} layers, {} units'.format(hidden_layers, units_layer),\n",
    "               ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(9, 3, figsize=(18, 54))\n",
    "\n",
    "hidden_layers = [5, 10, 15]\n",
    "units_layer = 8\n",
    "activations = ['logistic', 'tanh', 'relu']\n",
    "alphas = [0.01, 0.1, 1.0]\n",
    "axes = subaxes.ravel()\n",
    "\n",
    "i_ax = 0\n",
    "for (i, j, k), _ in np.ndenumerate(np.zeros((len(activations), len(alphas), len(hidden_layers)))):\n",
    "    print('.', end='')\n",
    "#     print(activations[i], alphas[j], hidden_layers[k], axes[i_ax])\n",
    "    train_test(model=MLPClassifier(hidden_layer_sizes=units * hidden_layers[k], \n",
    "                                   activation=activations[i], \n",
    "                                   alpha=alphas[j], \n",
    "                                   solver='lbfgs'),\n",
    "               X=X_D2, \n",
    "               y=y_D2, \n",
    "               title='Dataset 1: Neural Net classifier, {} layers, {} units, \\nalpha = {:.3f}, activation = {}'.format(\n",
    "                   hidden_layers[k], units_layer, alphas[j], activations[i]),\n",
    "               ax=axes[i_ax])\n",
    "    i_ax += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer[:, pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(24, 3, figsize=(20, 150))\n",
    "\n",
    "hidden_layers = [5, 10, 15]\n",
    "units_layer = 8\n",
    "activations = ['tanh', 'relu']\n",
    "alphas = [0.1, 0.5]\n",
    "axes = subaxes.ravel()\n",
    "pair_list = [[0,1], [1,2], [2,3]]  # sample of a few feature pairs\n",
    "\n",
    "i_ax = 0\n",
    "for pair in pair_list:\n",
    "    X, y = X_cancer[:, pair], y_cancer\n",
    "    for (i, j, k), _ in np.ndenumerate(np.zeros((len(activations), len(alphas), len(hidden_layers)))):\n",
    "        print('.', end='')\n",
    "    #     print(activations[i], alphas[j], hidden_layers[k], axes[i_ax])\n",
    "        train_test(model=MLPClassifier(hidden_layer_sizes=units * hidden_layers[k], \n",
    "                                       activation=activations[i], \n",
    "                                       alpha=alphas[j], \n",
    "                                       solver='lbfgs'),\n",
    "                   X=X, \n",
    "                   y=y, \n",
    "                   title='Dataset 1: Neural Net classifier, {} layers, {} units, \\nalpha = {:.3f}, activation = {}'.format(\n",
    "                       hidden_layers[k], units_layer, alphas[j], activations[i]),\n",
    "                   ax=axes[i_ax])\n",
    "        i_ax += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_R1[0::5], y_R1[0::5], random_state = 0)\n",
    "\n",
    "X_predict_input = np.linspace(-3, 3, 50).reshape(-1,1)\n",
    "\n",
    "fig, subaxes = plt.subplots(2, 3, figsize=(20, 9), dpi=70)\n",
    "\n",
    "for axisrow, activation in zip(subaxes, ['tanh', 'relu']):\n",
    "    for alpha, ax in zip([0.0001, 1.0, 100], axisrow):\n",
    "        reg = MLPRegressor(hidden_layer_sizes=[100,100],\n",
    "                             activation=activation,\n",
    "                             alpha=alpha,\n",
    "                             solver='lbfgs').fit(X_train, y_train)\n",
    "        \n",
    "        y_predict_output = reg.predict(X_predict_input)\n",
    "        _ = ax.set_xlim([-2.5, 0.75])\n",
    "        _ = ax.plot(X_predict_input, y_predict_output,\n",
    "                     '^', markersize = 10)\n",
    "        _ = ax.plot(X_train, y_train, 'o')\n",
    "        _ = ax.set_xlabel('Input feature')\n",
    "        _ = ax.set_ylabel('Target value')\n",
    "        _ = ax.set_title('MLP regression\\nalpha={}, activation={})'\n",
    "                          .format(alpha, activation))\n",
    "        plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application to real-world dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=[100, 100], alpha=5.0,random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "title = 'Breast cancer dataset'\n",
    "print_accuracy(title, clf.score(X_train_scaled, y_train), clf.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adspy_shared_utilities import load_crime_dataset\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for alpha, ax in zip([0.01, 0.1, 1.0, 5.0], subaxes.ravel()):\n",
    "    train_test(model=MLPClassifier(hidden_layer_sizes=[100, 100], alpha=alpha, solver='lbfgs'),\n",
    "           X=X_D2, \n",
    "           y=y_D2, \n",
    "           title='Dataset 2: NN classifier, alpha = {:.3f}'.format(alpha),\n",
    "           ax=ax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(model=MLPClassifier(hidden_layer_sizes=[100, 100], alpha=5.0, solver='lbfgs'),\n",
    "           X=X_cancer, \n",
    "           y=y_cancer, \n",
    "           title='Breast cancer dataset',\n",
    "           scaler=MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
