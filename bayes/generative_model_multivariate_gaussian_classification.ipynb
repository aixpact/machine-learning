{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model Classification - Multivariate Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we return to winery classification, using the full set of 13 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../../_data/wine.data.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split samples\n",
    "\n",
    " - split 178 instances into:\n",
    "   - training set (trainx, trainy) of size 130\n",
    "   - test set (testx, testy) of size 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130], 1:14]\n",
    "trainy = data[perm[0:130], 0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that fits a Gaussian generative model to the data.\n",
    "For each class (`j=1,2,3`), we have:\n",
    "* `pi[j]`: the class weight\n",
    "* `mu[j,:]`: the mean, a 13-dimensional vector\n",
    "* `sigma[j,:,:]`: the 13x13 covariance matrix\n",
    "\n",
    "This means that `pi` is a 4x1 array (Python arrays are indexed starting at zero, and we aren't using `j=0`), `mu` is a 4x13 array and `sigma` is a 4x13x13 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x, y, labels=[1,2,3]):\n",
    "    n = len(labels)  # labels 1,2,...,k\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((n, d))\n",
    "    sigma = np.zeros((n, d, d))\n",
    "    pi = np.zeros(n)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        indices = (y==label)\n",
    "        mu[i] = np.mean(x[indices, :], axis=0)\n",
    "        sigma[i] = np.cov(x[indices, :], rowvar=0, bias=1)\n",
    "        pi[i] = float(sum(indices))/float(len(y))\n",
    "    return mu, sigma, pi, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Gaussian generative model to the training data\n",
    "mu, sigma, pi, labels = fit_generative_model(trainx, trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "def test_model(mu, sigma, pi, labels, features, tx, ty):\n",
    "    score = np.zeros((len(ty), len(labels)))\n",
    "    \n",
    "    for i in range(len(ty)):\n",
    "        for j, label in enumerate(labels):\n",
    "            # max(log(probability of class * probability of feature)) = max(log(Class Weights) + log(PDF))\n",
    "            score[i, j] = np.log(pi[j]) + multivariate_normal.logpdf(\n",
    "                tx[i, features], mean=mu[j, features], cov=sigma[:,features,:][:, :,features][j,:,:])\n",
    "    predictions = np.asarray(labels)[np.argmax(score, axis=1)]\n",
    "    \n",
    "    # Tally up score\n",
    "    errors = np.sum(predictions!=ty)\n",
    "    return features, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = 100\n",
    "min_ftrs = []\n",
    "best_feature = 6\n",
    "labels = [1,2,3]\n",
    "for i in range(13):\n",
    "    for j in range(13):\n",
    "        k = best_feature\n",
    "        if j == i: continue\n",
    "        if i in [k,]: continue \n",
    "        if j in [i, k]: continue\n",
    "        features, errors = test_model(mu, sigma, pi, labels, [i,j,k], testx, testy)\n",
    "        if errors < min_error:\n",
    "            min_error = min(min_error, errors)\n",
    "            min_ftrs = features\n",
    "#             print(features, min_error)\n",
    "        if errors == 0: break\n",
    "            \n",
    "print('Feature set with lowest test error: {}[{}], {}[{}], {}[{}]\\ntest errors: {}'.format(\n",
    "    featurenames[min_ftrs[0]], min_ftrs[0], featurenames[min_ftrs[1]], min_ftrs[1], featurenames[min_ftrs[2]], min_ftrs[2], min_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
