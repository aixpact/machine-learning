{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Load dataset](#Load-dataset)\n",
    "- [The Default data set](#Figure-4.1---Default-data-set)\n",
    "- [4.3 Logistic Regression](#4.3-Logistic-Regression)\n",
    "- [4.4 Linear Discriminant Analysis](#4.4-Linear-Discriminant-Analysis)\n",
    "- [Lab: 4.6.3 Linear Discriminant Analysis](#4.6.3-Linear-Discriminant-Analysis)\n",
    "- [Lab: 4.6.4 Quadratic Discriminant Analysis](#4.6.4-Quadratic-Discriminant-Analysis)\n",
    "- [Lab: 4.6.5 K-Nearest Neighbors](#4.6.5-K-Nearest-Neighbors)\n",
    "- [Lab: 4.6.6 An Application to Caravan Insurance Data](#4.6.6-An-Application-to-Caravan-Insurance-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug fixes - statsmodels not compatible with current stable version of scipy/pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels bug fix:\n",
    "from pandas.core import datetools\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Workaround to fix bug in statsmodels .summary() - missing stats.chisqprob function\n",
    "# https://github.com/statsmodels/statsmodels/issues/3931\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../../_data/Default.xlsx')\n",
    "\n",
    "# Note: factorize() returns two objects: a label array and an array with the unique values.\n",
    "# We are only interested in the first object. \n",
    "df['default2'] = df.default.factorize()[0]\n",
    "df['student2'] = df.student.factorize()[0]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().sum()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a fraction of the samples where target value (default) is 'no'\n",
    "df_no = df[df.default2==0].sample(frac=0.1)\n",
    "\n",
    "# Take all samples where target value is 'yes'\n",
    "df_yes = df[df.default2==1]\n",
    "df_ = df_no.append(df_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Figure 4.1 - Default data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "gs = mpl.gridspec.GridSpec(1, 4)\n",
    "\n",
    "ax1 = plt.subplot(gs[0, :-2])\n",
    "ax2 = plt.subplot(gs[0, -2])\n",
    "ax3 = plt.subplot(gs[0, -1])\n",
    "\n",
    "ax1.scatter(df_[df_.default == 'No'].balance, df_[df_.default == 'No'].income, s=40, marker='o',\n",
    "            edgecolor='lightblue', facecolor='None', alpha=1) # linewidths and facecolor='None' don't go together\n",
    "ax1.scatter(df_[df_.default == 'Yes'].balance, df_[df_.default == 'Yes'].income, s=40, c='orange', marker='+',\n",
    "            linewidths=1)\n",
    "\n",
    "ax1.set_ylim(ymin=0)\n",
    "ax1.set_ylabel('Income')\n",
    "ax1.set_xlim(xmin=-100)\n",
    "ax1.set_xlabel('Balance')\n",
    "\n",
    "c_palette = {'No':'lightblue', 'Yes':'orange'}\n",
    "sns.boxplot('default', 'balance', data=df, orient='v', ax=ax2, palette=c_palette)\n",
    "sns.boxplot('default', 'income', data=df, orient='v', ax=ax3, palette=c_palette)\n",
    "gs.tight_layout(plt.gcf());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Logistic Regression\n",
    "### Figure 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.balance.values.reshape(-1,1) \n",
    "y = df.default2\n",
    "\n",
    "# Create array of test data\n",
    "X_test = np.arange(df.balance.min(), df.balance.max()).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = skl_lm.LogisticRegression(solver='newton-cg').fit(X_train, y)\n",
    "\n",
    "# Calculate the classification probability and predicted classification.\n",
    "prob = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise regression value, label, probability(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# Left plot\n",
    "_ = sns.regplot(df.balance, df.default2, order=1, ci=None,\n",
    "            scatter_kws={'color':'orange'},\n",
    "            line_kws={'color':'lightblue', 'lw':2}, ax=ax1)\n",
    "\n",
    "# middle plot\n",
    "_ = ax2.scatter(X_train, y, color='orange')\n",
    "_ = ax2.plot(X_test, clf.predict(X_test), color='lightblue')\n",
    "\n",
    "\n",
    "# Right plot\n",
    "_ = ax3.scatter(X_train, y, color='orange')\n",
    "_ = ax3.plot(X_test, prob[:, 1], color='lightblue')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    _ = ax.hlines(1, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    _ = ax.hlines(0, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    _ = ax.set_ylabel('Probability of default')\n",
    "    _ = ax.set_xlabel('Balance')\n",
    "    _ = ax.set_yticks([0, 0.25, 0.5, 0.75, 1.])\n",
    "    _ = ax.set_xlim(xmin=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.default2\n",
    "X_train = df.balance.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a bias/intercept (column of ones) to an array\n",
    "\n",
    "The original values with a constant (column of ones) as the first or last column.  \n",
    "Return type: array, recarray or DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df.balance)\n",
    "X_train[:10]\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using newton-cg solver, the coefficients are equal/closest to the ones in the book. \n",
    "# I do not know the details on the differences between the solvers.\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg').fit(X_train, y)\n",
    "\n",
    "print(clf)\n",
    "print('classes: ',clf.classes_)\n",
    "print('coefficients: ',clf.coef_)\n",
    "print('intercept :', clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = sm.add_constant(df.balance)  ## Adds a column of ones to an array\n",
    "est = smf.Logit(y.ravel(), X_train).fit()\n",
    "est.summary().tables[1]\n",
    "# const = intercept = bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df.student2)\n",
    "X_train[:3]\n",
    "y = df.default2\n",
    "\n",
    "est = smf.Logit(y, X_train).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4.3 - Multiple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df[['balance', 'income', 'student2']])\n",
    "est = smf.Logit(y, X_train).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4.3 - Confounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance and default vectors for students\n",
    "X_train = df[df.student == 'Yes'].balance.values.reshape(df[df.student == 'Yes'].balance.size,1) \n",
    "y = df[df.student == 'Yes'].default2\n",
    "\n",
    "# balance and default vectors for non-students\n",
    "X_train2 = df[df.student == 'No'].balance.values.reshape(df[df.student == 'No'].balance.size,1) \n",
    "y2 = df[df.student == 'No'].default2\n",
    "\n",
    "# Vector with balance values for plotting\n",
    "X_test = np.arange(df.balance.min(), df.balance.max()).reshape(-1,1)\n",
    "\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg').fit(X_train, y)\n",
    "clf2 = skl_lm.LogisticRegression(solver='newton-cg').fit(X_train2, y2)\n",
    "\n",
    "prob = clf.predict_proba(X_test)\n",
    "prob2 = clf2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix / pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot(y, y_pred, labels=['Negative', 'Positive']):\n",
    "    dict_labels = {k:v for k, v in zip(np.unique(y), labels)}\n",
    "    try:\n",
    "        y_name, y_pred_name = y.name, y_pred.name\n",
    "    except:\n",
    "        y_name, y_pred_name = 'True label', 'Predicted label'\n",
    "    df = pd.DataFrame({y_name: y, y_pred_name: y_pred})  \n",
    "    df.replace(to_replace=dict_labels, inplace=True)\n",
    "    return df.groupby([y_name, y_pred_name]).size().unstack(y_pred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot(df.student, df.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pivot(df.student, df.default)\n",
    "df_p['Support'] = df_p.sum(1)\n",
    "# df_p.append(df_p.sum(0), ignore_index=True)\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating plot\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Left plot\n",
    "ax1.plot(X_test, pd.DataFrame(prob)[1], color='orange', label='Student')\n",
    "ax1.plot(X_test, pd.DataFrame(prob2)[1], color='lightblue', label='Non-student')\n",
    "\n",
    "ax1.hlines(127/2817, colors='orange', label='Overall Student',\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed')\n",
    "ax1.hlines(206/6850, colors='lightblue', label='Overall Non-Student',\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed')\n",
    "\n",
    "ax1.set_ylabel('Default Rate')\n",
    "ax1.set_xlabel('Credit Card Balance')\n",
    "ax1.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.])\n",
    "ax1.set_xlim(450,2500)\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "# Right plot\n",
    "sns.boxplot('student', 'balance', data=df, orient='v', ax=ax2,  palette=c_palette);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Linear Discriminant Analysis\n",
    "### Table 4.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['balance', 'income', 'student2']].as_matrix()\n",
    "y = df.default2.as_matrix()\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "y_pred = lda.fit(X, y).predict(X)\n",
    "\n",
    "df_ = pd.DataFrame({'True default status': y,\n",
    "                    'Predicted default status': y_pred})\n",
    "X.shape, y.shape, df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot(df_['Predicted default status'], df_['True default status'], ['No', 'Yes']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot(y, y_pred, ['No', 'Yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4.5\n",
    "Instead of using the probability of 50% as decision boundary, we say that a probability of default of 20% is to be classified as 'Yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_prob = 0.2\n",
    "y_prob = lda.fit(X, y).predict_proba(X)\n",
    "\n",
    "df_ = pd.DataFrame({'True default status': y,\n",
    "                    'Predicted default status': y_prob[:,1] > decision_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot(df_['Predicted default status'], df_['True default status'], ['No', 'Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 Linear Discriminant Analysis\n",
    "\n",
    "Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance between classes. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.\n",
    "\n",
    "LDA is a classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.\n",
    "The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.\n",
    "\n",
    "The fitted model can also be used to reduce the dimensionality of the input by projecting it to the most discriminative directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.lda import LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "X_r2 = lda.fit(X, y).transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): {}'.format(\n",
    "      str(pca.explained_variance_ratio_)))\n",
    "\n",
    "plt.figure()\n",
    "for c, i, target_name in zip(\"rgb\", [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], c=c, label=target_name)\n",
    "plt.legend()\n",
    "plt.title('PCA of IRIS dataset')\n",
    "\n",
    "plt.figure()\n",
    "for c, i, target_name in zip(\"rgb\", [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r2[y == i, 0], X_r2[y == i, 1], c=c, label=target_name)\n",
    "plt.legend()\n",
    "plt.title('LDA of IRIS dataset')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../_data/Smarket.csv', usecols=range(1, 10), index_col=0, parse_dates=True) ## parse datetime\n",
    "df.sample(10)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][['Lag1','Lag2']]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "X_test = df['2005':][['Lag1','Lag2']]\n",
    "y_test = df['2005':]['Direction']\n",
    "\n",
    "lda = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "pred = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Priors - class means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_train=='Down'), np.mean(y_train=='Up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.priors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature means per class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df[:'2004']['Direction']=='Down'\n",
    "df.loc[M.values, 'Lag1'].mean()\n",
    "\n",
    "M = df[:'2004']['Direction']=='Down'\n",
    "df.loc[M.values, 'Lag2'].mean()\n",
    "\n",
    "M = df[:'2004']['Direction']=='Up'\n",
    "df.loc[M.values, 'Lag1'].mean()\n",
    "\n",
    "M = df[:'2004']['Direction']=='Up'\n",
    "df.loc[M.values, 'Lag2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.means_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These do not seem to correspond to the values from the R output in the book?\n",
    "lda.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_p = lda.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_p[:, 1]>0.5, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_p[:, 1]>0.9, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA as dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][['Lag1', 'Lag2','Lag3','Lag4','Lag5']]\n",
    "y_train = (df[:'2004']['Direction']=='Down').values*1\n",
    "# y_train\n",
    "\n",
    "X_test = df['2005':][['Lag1', 'Lag2','Lag3','Lag4','Lag5']]\n",
    "y_test = (df['2005']['Direction']=='Down').values*1\n",
    "# y_test\n",
    "\n",
    "lda2 = LinearDiscriminantAnalysis(n_components=2).fit(X_train, y_train)\n",
    "pred = lda2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda2.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda2.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These do not seem to correspond to the values from the R output in the book?\n",
    "lda2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda2.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda2.predict_proba(X_test)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of predictions around decision boundary # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.03\n",
    "np.unique(pred_p[:, 1] < 0.5+margin, return_counts=True), 'smaller than .5+margin'\n",
    "np.unique(0.5-margin < pred_p[:, 1], return_counts=True), 'bigger than .5-margin'\n",
    "'Predictions between margin({}) [false true] : {}'.format(margin, \n",
    "np.unique(pred_p[:, 1] < 0.5+margin, return_counts=True)[1] + np.unique(0.5-margin < pred_p[:, 1], return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_p[:, 1]), np.var(pred_p[:, 1])**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.4 Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.5 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.6 An Application to Caravan Insurance Data\n",
    "\n",
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In R, I exported the dataset from package 'ISLR' to a csv file\n",
    "df = pd.read_csv('../../_data/Caravan.csv')\n",
    "y = df.Purchase\n",
    "X = df.drop('Purchase', axis=1).astype('float64')\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "X_train = X_scaled[1000:,:]\n",
    "y_train = y[1000:]\n",
    "X_test = X_scaled[:1000,:]\n",
    "y_test = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(n_neighbors=1, weights='uniform'):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    return(pred, score, clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, n_neighbors, title='Confusion matrix (Normalized)',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Normalized confusion matrix: KNN-{}'.format(n_neighbors))\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(2), classes)\n",
    "    plt.yticks(np.arange(2), classes)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('True label',rotation='horizontal', ha='right')\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,3,5]:\n",
    "    pred, score, classes = KNN(i)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized.T, classes, n_neighbors=i)\n",
    "    cm_df = pd.DataFrame(cm.T, index=classes, columns=classes)\n",
    "    cm_df.index.name = 'Predicted'\n",
    "    cm_df.columns.name = 'True'\n",
    "    print(cm_df)    \n",
    "    print(pd.DataFrame(precision_score(y_test, pred, average=None),\n",
    "                       index=classes, columns=['Precision']))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = skl_lm.LogisticRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(X_test)\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test, pred), index=regr.classes_,\n",
    "                     columns=regr.classes_)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_p = regr.predict_proba(X_test)\n",
    "\n",
    "cm_df = pd.DataFrame({'True': y_test, 'Pred': pred_p[:,1] > .25})\n",
    "\n",
    "cm_df.Pred.replace(to_replace={True:'Yes', False:'No'}, inplace=True)\n",
    "print(cm_df.groupby(['True', 'Pred']).size().unstack('True').T)\n",
    "\n",
    "print(classification_report(y_test, cm_df.Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
