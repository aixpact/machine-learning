{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means and Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data set: **`Animals with Attributes`** contains information about 50 animals.  \n",
    "For each, it has 85 real-valued features that capture various properties of the animal: where it lives, what it eats, and so on.  \n",
    "You can download the data set from:  http://attributes.kyb.tuebingen.mpg.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../../_data | grep -1 classes.txt\n",
    "!find ../../_data | grep -1 predicate-matrix-continuous.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data set. The file `'classes.txt'` contains the names of the 50 animals. The file `'predicate-matrix-continuous.txt'` contains the data itself: 85 attributes per animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -2 ../../_data/Animals_with_Attributes/predicate-matrix-continuous.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load txt matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('../../_data/Animals_with_Attributes/predicate-matrix-continuous.txt')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head '../../_data/Animals_with_Attributes/classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../_data/Animals_with_Attributes/classes.txt', header=None, index_col=0, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = df[1]\n",
    "df_classes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run Lloyd's algorithm to obtain a flat clustering of the data. In the code below, we ask for k=15 clusters, but you should experiment with other choices.\n",
    "\n",
    "We ask for random initialization, which means that different runs of the algorithm will potentially have different outcomes. It is worth running the algorithm several times to see how the results change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train K-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "kmeans = KMeans(n_clusters=k, init='random').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster distribution and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_\n",
    "Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters by dictionary - cluster:[values,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {cluster:[] for cluster in kmeans.labels_}\n",
    "_ = [clusters[cluster].append(label) for cluster, label in zip(kmeans.labels_, df_classes)]\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of distance to closest cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "mpl.rc('axes.spines', left=True, top=False, right=False, bottom=True)  # hide axis/spines\n",
    "mpl.rc('xtick', color='k')  # hide xticks\n",
    "\n",
    "dist_cluster = []\n",
    "for k in range(1, 18):\n",
    "    kmeans = KMeans(n_clusters=k, init='random').fit(X)\n",
    "    dist_cluster.append(kmeans.inertia_)\n",
    "    \n",
    "_ = plt.plot(range(1, 18), dist_cluster, '-o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km6 = KMeans(n_clusters=6, init='random').fit(X)\n",
    "km14 = KMeans(n_clusters=14, init='random').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(18, 6))\n",
    "\n",
    "ax1.scatter(X[:,0], X[:,1], s=40, c=km6.labels_, cmap=plt.cm.prism) \n",
    "ax1.set_title('K-Means Clustering Results with K=6')\n",
    "ax1.scatter(km6.cluster_centers_[:, 0], km6.cluster_centers_[:, 1], marker='+', s=100, c='k', linewidth=2)\n",
    "\n",
    "ax2.scatter(X[:, 0], X[:, 1], s=40, c=km14.labels_, cmap=plt.cm.prism) \n",
    "ax2.set_title('K-Means Clustering Results with K=14')\n",
    "ax2.scatter(km14.cluster_centers_[:, 0], km14.cluster_centers_[:, 1], marker='+', s=100, c='k', linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(scale(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit_transform(scale(X));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pca.fit_transform(X) , columns=['PC1', 'PC2'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Loadings - Eigen Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_loadings = pd.DataFrame(pca.components_.T, columns=['V1', 'V2'])\n",
    "pca_loadings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "mpl.rc('axes.spines', left=True, top=False, right=False, bottom=True)  # hide axis/spines\n",
    "mpl.rc('xtick', color='k')  # hide xticks\n",
    "\n",
    "dist_cluster = []\n",
    "for k in range(1, 18):\n",
    "    kmeans = KMeans(n_clusters=k, init='random').fit(df)\n",
    "    dist_cluster.append(kmeans.inertia_)\n",
    "    \n",
    "_ = plt.plot(range(1, 18), dist_cluster, '-o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km4 = KMeans(n_clusters=4, init='random').fit(df)\n",
    "km8 = KMeans(n_clusters=8, init='random').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# https://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "\n",
    "colors = [\"#67E568\",\"#257F27\",\"#08420D\",\"#FFF000\",\"#FFB62B\",\"#E56124\",\"#E53E30\",\"#7F2353\",\"#F911FF\",\"#9F8CA6\"]\n",
    "\n",
    "cpal = sns.color_palette(colors)\n",
    "sns.palplot(cpal, 1)\n",
    "cmap_mpl = mpl.colors.ListedColormap(cpal.as_hex()) # discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(18, 6))\n",
    "\n",
    "ax1.scatter(df['PC1'], df['PC2'], s=40, c=km4.labels_, cmap=cmap_mpl) \n",
    "ax1.set_title('K-Means Clustering Results with K=4')\n",
    "ax1.scatter(km4.cluster_centers_[:, 0], km4.cluster_centers_[:, 1], marker='+', s=100, c='k', linewidth=2)\n",
    "\n",
    "ax2.scatter(df['PC1'], df['PC2'], s=40, c=km8.labels_, cmap=cmap_mpl) \n",
    "ax2.set_title('K-Means Clustering Results with K=8')\n",
    "ax2.scatter(km8.cluster_centers_[:, 0], km8.cluster_centers_[:, 1], marker='+', s=100, c='k', linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare clusters with and without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_pca = {cluster:[] for cluster in km8.labels_}\n",
    "_ = [clusters_pca[cluster].append(label) for cluster, label in zip(km8.labels_, df_classes)]\n",
    "clusters_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import rcParams\n",
    "\n",
    "mpl.rc('axes.spines', left=False, top=False, right=False, bottom=False)\n",
    "mpl.rc('xtick', color='w')  # hide xticks\n",
    "mpl.rc('ytick', color='w')  # hide xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax1 = plt.subplots(figsize=(12, 12))\n",
    "colors = [\"#67E568\",\"#257F27\",\"#08420D\",\"#FFF000\",\"#FFB62B\",\"#E56124\",\"#E53E30\",\"#7F2353\",\"#F911FF\",\"#9F8CA6\"]\n",
    "\n",
    "_ = ax1.set_xlim(-300, 200)\n",
    "_ = ax1.set_ylim(-150, 150)\n",
    "\n",
    "# Plot Principal Components 1 and 2\n",
    "for i in df.index:\n",
    "    label = km8.labels_[i]\n",
    "    _ = ax1.annotate(df_classes.iloc[i], (df.PC1.loc[i], df.PC2.loc[i]), ha='center', \n",
    "                     color=colors[label], size=14, alpha=.9)\n",
    "\n",
    "ax1.set_xlabel('Principal Component 1', size=14)\n",
    "ax1.set_ylabel('Principal Component 2', size=14)\n",
    "    \n",
    "# Plot Eigen Vectors\n",
    "mp = 1000\n",
    "ax1.arrow(0, 0, pca_loadings.V1[0]*mp, pca_loadings.V2[0]*mp, color='blue')\n",
    "ax1.arrow(0, 0, pca_loadings.V1[1]*mp, pca_loadings.V2[1]*mp, color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the built-in hierarchical clustering module of `scipy` to apply **Ward's method** to our data.\n",
    "\n",
    "Lloyd's algorithm potentially returns a different solution each time it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sch.linkage(X, method='ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show dendogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set defaults dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import rcParams\n",
    "\n",
    "# plt.rcParams.find_all\n",
    "\n",
    "mpl.rc('figure', figsize=[10., 12.])\n",
    "mpl.rc('axes.spines', left=False, top=False, right=False, bottom=False)  # hide axis/spines\n",
    "mpl.rc('xtick', color='w')  # hide xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 12))\n",
    "\n",
    "# Display dendrogram\n",
    "info = sch.dendrogram(z, orientation='left', labels=df_classes.values, leaf_font_size=12)\n",
    "leaves_in_reverse = info['ivl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats and questions regarding clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some things to think about:\n",
    "\n",
    "**Multiple runs of Lloyd's algorithm**  \n",
    "Lloyd's algorithm potentially returns a different solution each time it is run.  \n",
    "Is there any reason to run it more than once?  \n",
    "For instance, is there a sensible way of combining the information from several runs,  \n",
    "of interpreting the similarities and differences?\n",
    "\n",
    "**Sensitivity to the choice of features**  \n",
    "Both clustering methods are highly sensitive to the choice of features.  \n",
    "How would you feel if the results changed dramatically when just one or two features were dropped? \n",
    "\n",
    "**Criteria for success**  \n",
    "This is clearly an application in which we are hoping that clustering will discover 'natural groups' in the data.  \n",
    "To what extent do the algorithms succeed at this? Are the clusters mostly reasonable?  \n",
    "Can we, in general, hope that tha clustering will perfectly capture what we want?  \n",
    "Under what conditions would we be pleased with the clustering?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
