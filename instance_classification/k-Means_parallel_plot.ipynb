{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering parallel coordinates plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cluster analysis to generate a big picture model of the weather at a local station using a minute-graunlarity data.   \n",
    "In this dataset, we have in the order of millions records. How do we create 12 clusters our of them?\n",
    "\n",
    "The dataset we will use is in a large CSV file called *minute_weather.csv*.  \n",
    "The download link is: https://drive.google.com/open?id=0B8iiZ7pSaSFZb3ItQ1l4LWRMTjg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "# import utils\n",
    "from itertools import cycle, islice\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../.. | grep -i minute_weather.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../_data/minute_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\">Minute Weather Data Description</p>\n",
    "<br>\n",
    "The **minute weather dataset** comes from the same source as the daily weather dataset that we used in the decision tree based classifier notebook. The main difference between these two datasets is that the minute weather dataset contains raw sensor measurements captured at one-minute intervals. Daily weather dataset instead contained processed and well curated data. The data is in the file **minute_weather.csv**, which is a comma-separated file.\n",
    "\n",
    "As with the daily weather data, this data comes from a weather station located in San Diego, California. The weather station is equipped with sensors that capture weather-related measurements such as air temperature, air pressure, and relative humidity. Data was collected for a period of three years, from September 2011 to September 2014, to ensure that sufficient data for different seasons and weather conditions is captured.\n",
    "\n",
    "Each row in **minute_weather.csv** contains weather data captured for a one-minute interval. Each row, or sample, consists of the following variables:\n",
    "\n",
    "* **rowID:** \tunique number for each row\t(*Unit: NA*)\n",
    "* **hpwren_timestamp:**\ttimestamp of measure\t(*Unit: year-month-day hour:minute:second*)\n",
    "* **air_pressure:** air pressure measured at the timestamp\t(*Unit: hectopascals*)\n",
    "* **air_temp:**\tair temperature measure at the timestamp\t(*Unit: degrees Fahrenheit*)\n",
    "* **avg_wind_direction:**\twind direction averaged over the minute before the timestamp\t(*Unit: degrees, with 0 means coming from the North, and increasing clockwise*)\n",
    "* **avg_wind_speed:**\twind speed averaged over the minute before the timestamp\t(*Unit: meters per second*)\n",
    "* **max_wind_direction:**\thighest wind direction in the minute before the timestamp\t(*Unit: degrees, with 0 being North and increasing clockwise*)\n",
    "* **max_wind_speed:**\thighest wind speed in the minute before the timestamp\t(*Unit: meters per second*)\n",
    "* **min_wind_direction:**\tsmallest wind direction in the minute before the timestamp\t(*Unit: degrees, with 0 being North and inceasing clockwise*)\n",
    "* **min_wind_speed:**\tsmallest wind speed in the minute before the timestamp\t(*Unit: meters per second*)\n",
    "* **rain_accumulation:**\tamount of accumulated rain measured at the timestamp\t(*Unit: millimeters*)\n",
    "* **rain_duration:**\tlength of time rain has fallen as measured at the timestamp\t(*Unit: seconds*)\n",
    "* **relative_humidity:**\trelative humidity measured at the timestamp\t(*Unit: percent*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = np.random.permutation(data.index)[:100000]\n",
    "\n",
    "sampled_df = data.iloc[sample_ind]\n",
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[sampled_df['rain_accumulation'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[sampled_df['rain_duration'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed feature distributions\n",
    "\n",
    "- find features with a distribution concentrated in one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "{ftr:Counter(sampled_df[ftr])[0]/sampled_df.shape[0] for ftr in sampled_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sampled_df['rain_accumulation']\n",
    "del sampled_df['rain_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Number of rows with NaN: {}'.format(sampled_df.isnull().any(1).sum())\n",
    "{ftr:sampled_df[ftr].isnull().sum() for ftr in sampled_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = sampled_df.shape[0]\n",
    "sampled_df = sampled_df.dropna()\n",
    "rows_after = sampled_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before - rows_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Select Features of Interest for Clustering\n",
    "<br><br></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['air_pressure', 'air_temp', 'avg_wind_direction', 'avg_wind_speed', 'max_wind_direction', \n",
    "        'max_wind_speed','relative_humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = sampled_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(select_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=12)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe with cluster center coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_centers(featuresUsed, centers):\n",
    "    colNames = featuresUsed + ['prediction']\n",
    "\n",
    "    # Zip with a column called 'prediction' (index)\n",
    "    Z = [np.append(A, index) for index, A in enumerate(centers)]\n",
    "\n",
    "    # Convert to pandas data frame for plotting\n",
    "    P = pd.DataFrame(Z, columns=colNames)\n",
    "    P['prediction'] = P['prediction'].astype(int)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = df_centers(features, centers)\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_plot(data):\n",
    "    my_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(data)))\n",
    "    \n",
    "    plt.figure(figsize=(15, 8)).gca().axes.set_ylim([-3, +3])\n",
    "    \n",
    "    parallel_coordinates(data, 'prediction', color=my_colors, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_plot(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dry Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_plot(P[P['relative_humidity'] < -0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_plot(P[P['air_temp'] > 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cool Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_plot(P[(P['relative_humidity'] > 0.5) & (P['air_temp'] < 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
