{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use logistic regression to learn a classifier from review data.\n",
    "\n",
    "Download the data from https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences. The folder `sentiment_labelled_sentences` (containing the data file `full_set.txt`) should be in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook, load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The **`sentiment`** data set consists of 3000 sentences which come from reviews on `imdb.com`, `amazon.com`, and `yelp.com`. Each sentence is labeled according to whether it comes from a positive review or negative review;\n",
    " - '1' if it came from a positive review\n",
    " - '0' if it came from a negative review\n",
    "\n",
    "We will change the negative review label to '-1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data set.\n",
    "with open(\"../../_data/sentiment_labelled_sentences/full_set.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "## Remove leading and trailing white space\n",
    "content = [x.strip() for x in content]\n",
    "\n",
    "## Separate the sentences from the labels\n",
    "sentences = [x.split(\"\\t\")[0] for x in content]\n",
    "labels = [x.split(\"\\t\")[1] for x in content]\n",
    "\n",
    "## Transform the labels from '0 v.s. 1' to '-1 v.s. 1'\n",
    "y = np.array(labels, dtype='int8')\n",
    "y = 2*y - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the text data\n",
    "\n",
    "To transform this prediction problem into one amenable to linear classification, we will first need to preprocess the text data. We will do four transformations:\n",
    "\n",
    "1. Remove punctuation and numbers.\n",
    "2. Transform all words to lower-case.\n",
    "3. Remove _stop words_.\n",
    "4. Convert the sentences into vectors, using a bag-of-words representation.\n",
    "\n",
    "We begin with first two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## full_remove takes a string x and a list of characters removal_list \n",
    "## returns x with all the characters in removal_list replaced by ' '\n",
    "def full_remove(x, removal_list):\n",
    "    for w in removal_list:\n",
    "        x = x.replace(w, ' ')\n",
    "    return x\n",
    "\n",
    "## Remove digits\n",
    "digits = [str(x) for x in range(10)]\n",
    "digit_less = [full_remove(x, digits) for x in sentences]\n",
    "\n",
    "## Remove punctuation\n",
    "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less]\n",
    "\n",
    "## Make everything lower-case\n",
    "sents_lower = [x.lower() for x in punc_less]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "Stop words are words that are filtered out because they are believed to contain no useful information for the task at hand. These usually include articles such as 'a' and 'the', pronouns such as 'i' and 'they', and prepositions such 'to' and 'from'. We have put together a very small list of stop words, but these are by no means comprehensive. Feel free to use something different; for instance, larger lists can easily be found on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our stop words\n",
    "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from'])\n",
    "\n",
    "## Remove stop words\n",
    "sents_split = [x.split() for x in sents_lower]\n",
    "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the sentences look like so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_processed[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "In order to use linear classifiers on our data set, we need to transform our textual data into numeric data. The classical way to do this is known as the _bag of words_ representation. \n",
    "\n",
    "In this representation, each word is thought of as corresponding to a number in `{1, 2, ..., V}` where `V` is the size of our vocabulary. And each sentence is represented as a V-dimensional vector $x$, where $x_i$ is the number of times that word $i$ occurs in the sentence.\n",
    "\n",
    "To do this transformation, we will make use of the `CountVectorizer` class in `scikit-learn`. We will cap the number of features at 4500, meaning a word will make it into our vocabulary only if it is one of the 4500 most common words in the corpus. This is often a useful step as it can weed out spelling mistakes and words which occur too infrequently to be useful.\n",
    "\n",
    "Finally, we will also append a '1' to the end of each vector to allow our linear classifier to learn a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Transform to bag of words representation.\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, stop_words=None, max_features=4500)\n",
    "data_features = vectorizer.fit_transform(sents_processed)\n",
    "\n",
    "## Append '1' to the end of each vector.\n",
    "data_mat = data_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / test split\n",
    "\n",
    "Finally, we split the data into a training set of 2500 sentences and a test set of 500 sentences (of which 250 are positive and 250 negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into testing and training sets\n",
    "np.random.seed(0)\n",
    "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False), np.random.choice((np.where(y==1))[0], 250, replace=False))\n",
    "train_inds = list(set(range(len(labels))) - set(test_inds))\n",
    "\n",
    "train_data = data_mat[train_inds,]\n",
    "train_labels = y[train_inds]\n",
    "\n",
    "test_data = data_mat[test_inds,]\n",
    "test_labels = y[test_inds]\n",
    "\n",
    "print(\"train data: \", train_data.shape)\n",
    "print(\"test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a logistic regression model to the training data\n",
    "\n",
    "We could implement our own __logistic regression solver using stochastic gradient descent__, but fortunately, there is already one built into `scikit-learn`.\n",
    "\n",
    "Due to the randomness in the SGD procedure, different runs can yield slightly different solutions (and thus different error values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "## Fit logistic classifier on training data\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"none\",max_iter=1000, tol=1e-3)\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "## Pull out the parameters (w,b) of the logistic regression model\n",
    "w = clf.coef_[0,:]\n",
    "b = clf.intercept_\n",
    "\n",
    "## Get predictions on training and test data\n",
    "preds_train = clf.predict(train_data)\n",
    "preds_test = clf.predict(test_data)\n",
    "\n",
    "## Compute errors\n",
    "errs_train = np.sum((preds_train > 0.0) != (train_labels > 0.0))\n",
    "errs_test = np.sum((preds_test > 0.0) != (test_labels > 0.0))\n",
    "\n",
    "print(\"Training error: \", float(errs_train)/len(train_labels))\n",
    "print(\"Test error: \", float(errs_test)/len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the margin\n",
    "\n",
    "The logistic regression model produces not just classifications but also conditional probability estimates. \n",
    "\n",
    "We will say that `x` has **margin** `gamma` if (according to the logistic regression model):\n",
    "\n",
    "__`Pr(y=1|x) > (0.5)+gamma`__  \n",
    "or  \n",
    "__`Pr(y=1|x) < (0.5)-gamma`__  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **margin_counts** computes how many points in the test set are at least a margin(`gamma`) away from the decision boundary (0.5).\n",
    "input:  \n",
    " - the classifier `clf`\n",
    " - the test set `test_data`\n",
    " - a value of `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(clf, test_data):\n",
    "    \"\"\"Prediction probabilities\"\"\"\n",
    "    return clf.predict_proba(test_data)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_indices(clf, test_data, gamma):\n",
    "    \"\"\"Indices of test points at least a margin away from the decision boundary\"\"\"\n",
    "    preds = predictions(clf, test_data)\n",
    "    return np.where((preds > (0.5+gamma)) | (preds < (0.5-gamma)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_counts(clf, test_data, gamma):\n",
    "    \"\"\"Number of test points at least a margin away from the decision boundary\"\"\"\n",
    "    return len(margin_indices(clf, test_data, gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_counts_(clf, test_data, gamma):\n",
    "    \"\"\"Number of test points at least a margin away from the decision boundary\"\"\"\n",
    "    \n",
    "    ## Compute probability on each test point\n",
    "    preds = clf.predict_proba(test_data)[:,1]\n",
    "    \n",
    "    margin_inds = np.where((preds > (0.5+gamma)) | (preds < (0.5-gamma)))[0]\n",
    "    \n",
    "    return len(margin_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set's distribution of margin values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = np.arange(0, 0.5 ,0.01)\n",
    "\n",
    "f = np.vectorize(lambda g: margin_counts(clf, test_data, g))\n",
    "\n",
    "plt.plot(gammas, f(gammas)/len(test_data), linewidth=2, color='green')\n",
    "plt.xlabel('Margin', fontsize=14)\n",
    "plt.ylabel('Fraction of points above margin', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are points `x` with larger margin more likely to be classified correctly?\n",
    "\n",
    "The function **margin_errors** computes the fraction of misclassified points at least `gamma` away from the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return error of predictions that lie in intervals [0, 0.5 - gamma) and (0.5 + gamma, 1]\n",
    "def margin_errors(clf, test_data, test_labels, gamma):\n",
    "    \"\"\"Fraction of Misclassifications at least a margin away from the decision boundary\"\"\"\n",
    "    \n",
    "    preds = predictions(clf, test_data)\n",
    "    margin_inds = margin_indices(clf, test_data, gamma)\n",
    "    \n",
    "    ## Compute error on those data points.\n",
    "    num_errors = np.sum((preds[margin_inds] > 0.5) != (test_labels[margin_inds] > 0.0))\n",
    "    return num_errors / len(margin_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of margin and error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create grid of gamma values\n",
    "gammas = np.arange(0, 0.5, 0.01)\n",
    "\n",
    "## Compute margin_errors on test data for each value of g\n",
    "f = np.vectorize(lambda g: margin_errors(clf, test_data, test_labels, g))\n",
    "\n",
    "## Plot the result\n",
    "plt.plot(gammas, f(gammas), linewidth=2)\n",
    "plt.ylabel('Error rate', fontsize=14)\n",
    "plt.xlabel('Margin', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words with large influence\n",
    "\n",
    "Finally, we attempt to partially **interpret** the logistic regression model.\n",
    "Words whose coefficients in __`w`__ have the largest positive and negative values are the most influential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert vocabulary into a list:\n",
    "# CountVectorizer builts vector of words on alphabetical order; index 0 ~ aa..\n",
    "vocab = np.array([z[0] for z in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1])])\n",
    "vocab[:5], vocab[-5:]\n",
    "\n",
    "## Get indices of sorted coefs\n",
    "inds = np.argsort(clf.coef_[0, :])\n",
    "inds\n",
    "\n",
    "## Words with large negative values\n",
    "neg_inds = inds[:50]\n",
    "print(\"\\nHighly negative words: \")\n",
    "print([str(x) for x in list(vocab[neg_inds])])\n",
    "\n",
    "## Words with large positive values\n",
    "pos_inds = inds[::-1][:50]\n",
    "print(\"\\nHighly positive words: \")\n",
    "print([str(x) for x in list(vocab[pos_inds])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take away\n",
    "\n",
    "Suppose you are building a classifier, and can tolerate an error rate of at most some value __`e`__. Unfortunately, every classifier you try has a higher error than this. \n",
    "\n",
    "Therefore, you decide that the classifier is allowed to occasionally **abstain**: that is, to say *\"don't know\"*. When it actually makes a prediction, it must have error rate at most __`e`__. And subject to this constraint, it should abstain as infrequently as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
