{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Classification - manual implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework notebook we use **nearest neighbor classification** to classify back injuries for patients in a hospital, based on measurements of the shape and orientation of their pelvis and spine.\n",
    "\n",
    "The data set contains information from **310** patients. For each patient, there are: six measurements (the x) and a label (the y). The label has **3** possible values, `’NO’` (normal), `’DH’` (herniated disk), or `’SL’` (spondilolysthesis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the dataset. We divide the data into a training set of 248 patients and a separate test set of 62 patients. The following arrays are created:\n",
    "\n",
    "* **`trainx`** : The training data's features, one point per row.\n",
    "* **`trainy`** : The training data's labels.\n",
    "* **`testx`** : The test data's features, one point per row.\n",
    "* **`testy`** : The test data's labels.\n",
    "\n",
    "We will use the training set (`trainx` and `trainy`), with nearest neighbor classification, to predict labels for the test data (`testx`). We will then compare these predictions with the correct labels, `testy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we code the three labels as `0. = ’NO’, 1. = ’DH’, 2. = ’SL’`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = !find ../.. | grep -i column_3C.dat\n",
    "data_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../../_data/column_3C.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set and code labels as 0 = ’NO’, 1 = ’DH’, 2 = ’SL’\n",
    "labels = [b'NO', b'DH', b'SL']\n",
    "data = np.loadtxt(data_file[0], converters={6: lambda s: labels.index(s)} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from labels\n",
    "x = data[:, 0:6]\n",
    "y = data[:, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_indices = list(range(0,20)) + list(range(40,188)) + list(range(230,310))\n",
    "test_indices = list(range(20,40)) + list(range(188,230))\n",
    "\n",
    "trainx = x[training_indices,:]\n",
    "trainy = y[training_indices]\n",
    "testx = x[test_indices,:]\n",
    "testy = y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN distance metrics\n",
    "\n",
    "To compute nearest neighbors in our data set, we need to first be able to compute distances between data points. \n",
    "A natural distance function is _Euclidean distance aka the L2-norm_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as   \n",
    "$$L2-norm = \\|x - y\\|^2 = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "\n",
    "Another distance metric is the _Manhattan distance or taxicab distance aka the L1-norm_:   \n",
    "$$L1-norm = \\|x - y\\| = \\sum_{i=1}^d |x_i - y_i|.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(x, y):\n",
    "    \"\"\"L1 (Manhattan) distance.\n",
    "    :param x, y: vectors x, y\n",
    "    :returns: distance\"\"\"\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(x, y):\n",
    "    \"\"\"L2 (Euclidean) distance.\n",
    "    :param x, y: vectors x, y\n",
    "    :returns: distance\"\"\"\n",
    "    return np.sum(np.square(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NN(trainx, samplex, norm):\n",
    "    '''Compute L2 distances from x to full dataset.\n",
    "    :param samplex: vector x\n",
    "    :returns: the index of its nearest neighbor in dataset'''\n",
    "    distances = [norm(samplex, trainx[i,]) for i in range(len(trainx))]\n",
    "    return np.argmin(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_classifier(trainx, trainy, samplex, norm):\n",
    "    \"\"\"Get NN index and return class\n",
    "    :param x: vector x\n",
    "    :returns: predicted class\n",
    "    \"\"\"\n",
    "    index = find_NN(trainx, samplex, norm)\n",
    "    return trainy[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(trainx, trainy, testx, norm=L2):\n",
    "    \"\"\"Nearest Neighbor Classifier\n",
    "    :params: trainx, trainy, testx, norm=L2\n",
    "    :returns: predicted labels for testset\n",
    "    \"\"\"\n",
    "    predicted_values = [NN_classifier(trainx, trainy, samplex, norm) for i, samplex in enumerate(testx)]\n",
    "    return np.asarray(predicted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_L2 = NN(trainx, trainy, testx, L2)\n",
    "\n",
    "assert( type( testy_L2).__name__ == 'ndarray' )\n",
    "assert( len(testy_L2) == 62 ) \n",
    "assert( np.all( testy_L2[50:60] == [ 0.,  0.,  0.,  0.,  2.,  0.,  2.,  0.,  0.,  0.] )  )\n",
    "assert( np.all( testy_L2[0:10] == [ 0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_L1 = NN(trainx, trainy, testx, L1)\n",
    "\n",
    "assert( type( testy_L1).__name__ == 'ndarray' )\n",
    "assert( len(testy_L1) == 62 ) \n",
    "assert( not all(testy_L1 == testy_L2) )\n",
    "assert( all(testy_L1[50:60]== [ 0.,  2.,  1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.]) )\n",
    "assert( all( testy_L1[0:10] == [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the L1 and L2 distance functions yield different error rates for nearest neighbor classification of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(testy, testy_pred):\n",
    "    return float(sum(testy!=testy_pred))/len(testy) \n",
    "\n",
    "print(\"Error rate of NN_L1: \", error_rate(testy, testy_L1) )\n",
    "print(\"Error rate of NN_L2: \", error_rate(testy, testy_L2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look a bit more deeply into the specific types of errors made by nearest neighbor classification, by constructing the <font color=\"magenta\">*confusion matrix*</font>.\n",
    "\n",
    "Since there are three labels, the confusion matrix is a 3x3 matrix that shows the number of misclassifications for each label. For example, the entry at row DH, column SL, contains the number of test points whose correct label was DH but which were classified as SL.\n",
    "\n",
    "<img style=\"width:200px\" src=\"../../_data/confusion_matrix.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testy, testy_L1)\n",
    "cm\n",
    "cm.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(testy, testy_pred, diag_zeros=False):\n",
    "    \"\"\"Get Confusion Matrix.\n",
    "    :params: correct labels, predicted NN labels \n",
    "    :params diag_zeros: keep matrix diagonal to zero's (remove the correct predictions)\n",
    "    :returns: 3x3 np.array representing the confusion matrix\"\"\"\n",
    "    n, m = len(np.unique(testy)), len(np.unique(testy_pred))\n",
    "    conf_matrix = np.zeros((n, m))\n",
    "    for (y, p), _ in np.ndenumerate(conf_matrix):\n",
    "            if not (y == p and diag_zeros):\n",
    "                conf_matrix[y, p] = sum([1 for label, pred in zip(testy, testy_pred) if label==y if pred==p])\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(testy, testy_L1)\n",
    "confusion(testy, testy_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(testy, testy_L2)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(testy, testy_L2).sum()   # total [r, c]\n",
    "confusion(testy, testy_L2).sum(0)  # by column (prediction) - sum of rows\n",
    "confusion(testy, testy_L2).sum(1)  # by row (label) - sum of cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(confusion(testy, testy_L2))\n",
    "confusion(testy, testy_L2).ravel()[np.argmax(confusion(testy, testy_L2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification differences in norms L1 vs. L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(testy_L1 != testy_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(confusion(testy, testy_L1) != confusion(testy, testy_L2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
